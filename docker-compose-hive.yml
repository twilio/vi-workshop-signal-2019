version: '3' 
services:
  namenode:
    image: bde2020/hadoop-namenode:1.1.0-hadoop2.8-java8
    container_name: namenode
    volumes:
      - ${PWD}/scripts/hdfs:/scripts:rw
      - ${PWD}/data:/signaldata:rw
    environment:
      - CLUSTER_NAME=test
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    healthcheck:
      interval: 5s
      retries: 10
    env_file:
      - ./hadoop-hive.env
    ports:
      - 8020:8020
      - 50070:50070
    networks:
      - spark-net
    hostname: "namenode"
  datanode:
    image: bde2020/hadoop-datanode:1.1.0-hadoop2.8-java8
    container_name: datanode
    depends_on: 
      - namenode
    volumes:
      - ${PWD}/hadoop/datanode/:/hadoop/dfs/data:rw
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    healthcheck:
      interval: 5s
      retries: 10
    env_file:
      - ./hadoop-hive.env
    ports:
      - 50075:50075
    networks:
      - spark-net
    hostname: "datanode"
  spark-master:
    image: bde2020/spark-master:2.4.3-hadoop2.7
    container_name: spark-master
    ports:
      - 8090:8090
      - 7077:7077
    environment:
      - SPARK_MASTER_WEBUI_PORT=8090
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    depends_on:
      - namenode
      - datanode
    healthcheck:
      interval: 5s
      retries: 10 
    env_file:
      - ./hadoop-hive.env
    networks:
      - spark-net
    hostname: "spark-master"
  spark-worker:
    image: bde2020/spark-worker:2.4.3-hadoop2.7
    container_name: spark-worker
    depends_on:
      - spark-master
    environment:
      - SPARK_WORKER_WEBUI_PORT=8091
      - SPARK_MASTER=spark://spark-master:7077
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - HIVE_CORE_CONF_javax_jdo_option_ConnectionURL=jdbc:postgresql://hive-metastore/metastore
    healthcheck:
      interval: 5s
      retries: 12
    ports:
      - 8091:8091
    env_file:
      - ./hadoop-hive.env
    networks:
      - spark-net
    hostname: "spark-worker"
  zeppelin:
    image: vi/docker-spark-zeppelin
    build:
      context: .
      args:
        APACHE_SPARK_VERSION: 2.4.3
        APACHE_HADOOP_VERSION: 2.8.0
        SPARK_MASTER: "spark://spark-master:7077" 
        ZEPPELIN_DOWNLOAD_URL: http://apache.cs.utah.edu/zeppelin 
        ZEPPELIN_VERSION: 0.8.1
        ZEPPELIN_PORT: 8080
        ZEPPELIN_INSTALL_DIR: /usr/lib
        ZEPPELIN_HOME: /usr/lib/zeppelin 
        ZEPPELIN_PKG_NAME: "zeppelin-${ZEPPELIN_VERSION:-0.8.1}-bin-all"
    container_name: zeppelin
    environment:
      CORE_CONF_fs_defaultFS: "hdfs://namenode:8020"
      SPARK_MASTER: "spark://spark-master:7077"
      MASTER: "spark://spark-master:7077"
      ZEPPELIN_PORT: 8080
      ZEPPELIN_JAVA_OPTS: >-
        -Dspark.driver.memory=1g
        -Dspark.executor.memory=1g
        -Dspark.cores.max=1
      ZEPPELIN_MEM: "-Xms1g -Xmx1g"
      ZEPPELIN_INTP_MEM: "-Xms1g -Xmx1g -XX:MaxPermSize=1024m"
      ZEPPELIN_NOTEBOOK_DIR: "/notebooks"
      ZEPPELIN_LOG_DIR: "/logs"
    ports:
      - 8080:8080
    env_file:
      - ./hadoop-hive.env
    volumes:
      - ${PWD}/data:/data:rw
      - ${PWD}/notebook:/notebooks:rw
      - ${PWD}/logs:/logs:rw
    depends_on:
      - spark-master
      - namenode
    networks:
      - spark-net
    hostname: "zeppelin"

networks:
  spark-net:
    external:
      name: spark-net
